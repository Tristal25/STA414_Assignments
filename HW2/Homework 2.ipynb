{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes for Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from future.standard_library import install_aliases\n",
    "install_aliases()\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "import os\n",
    "import gzip\n",
    "import struct\n",
    "import array\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def download(url, filename):\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    out_file = os.path.join('data', filename)\n",
    "    if not os.path.isfile(out_file):\n",
    "        urlretrieve(url, out_file)\n",
    "\n",
    "\n",
    "def mnist():\n",
    "    base_url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "\n",
    "    def parse_labels(filename):\n",
    "        with gzip.open(filename, 'rb') as fh:\n",
    "            magic, num_data = struct.unpack(\">II\", fh.read(8))\n",
    "            return np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
    "\n",
    "    def parse_images(filename):\n",
    "        with gzip.open(filename, 'rb') as fh:\n",
    "            magic, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
    "            return np.array(array.array(\"B\", fh.read()), dtype=np.uint8).reshape(num_data, rows, cols)\n",
    "\n",
    "    for filename in ['train-images-idx3-ubyte.gz',\n",
    "                     'train-labels-idx1-ubyte.gz',\n",
    "                     't10k-images-idx3-ubyte.gz',\n",
    "                     't10k-labels-idx1-ubyte.gz']:\n",
    "        download(base_url + filename, filename)\n",
    "\n",
    "    train_images = parse_images('data/train-images-idx3-ubyte.gz')\n",
    "    train_labels = parse_labels('data/train-labels-idx1-ubyte.gz')\n",
    "    test_images = parse_images('data/t10k-images-idx3-ubyte.gz')\n",
    "    test_labels = parse_labels('data/t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    return train_images, train_labels, test_images[:1000], test_labels[:1000]\n",
    "\n",
    "\n",
    "def load_mnist(N_data=None):\n",
    "    partial_flatten = lambda x: np.reshape(x, (x.shape[0], np.prod(x.shape[1:])))\n",
    "    one_hot = lambda x, k: np.array(x[:, None] == np.arange(k)[None, :], dtype=int)\n",
    "    train_images, train_labels, test_images, test_labels = mnist()\n",
    "    train_images = (partial_flatten(train_images) / 255.0 > .5).astype(float)\n",
    "    test_images = (partial_flatten(test_images) / 255.0 > .5).astype(float)\n",
    "    K_data = 10\n",
    "    train_labels = one_hot(train_labels, K_data)\n",
    "    test_labels = one_hot(test_labels, K_data)\n",
    "    if N_data is not None:\n",
    "        train_images = train_images[:N_data, :]\n",
    "        train_labels = train_labels[:N_data, :]\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "def plot_images(images, ax, ims_per_row=5, padding=5, digit_dimensions=(28, 28),\n",
    "                cmap=matplotlib.cm.binary, vmin=None, vmax=None):\n",
    "    \"\"\"Images should be a (N_images x pixels) matrix.\"\"\"\n",
    "    N_images = images.shape[0]\n",
    "    N_rows = np.int32(np.ceil(float(N_images) / ims_per_row))\n",
    "    pad_value = np.min(images.ravel())\n",
    "    concat_images = np.full(((digit_dimensions[0] + padding) * N_rows + padding,\n",
    "                             (digit_dimensions[1] + padding) * ims_per_row + padding), pad_value)\n",
    "    for i in range(N_images):\n",
    "        cur_image = np.reshape(images[i, :], digit_dimensions)\n",
    "        row_ix = i // ims_per_row\n",
    "        col_ix = i % ims_per_row\n",
    "        row_start = padding + (padding + digit_dimensions[0]) * row_ix\n",
    "        col_start = padding + (padding + digit_dimensions[1]) * col_ix\n",
    "        concat_images[row_start: row_start + digit_dimensions[0],\n",
    "                      col_start: col_start + digit_dimensions[1]] = cur_image\n",
    "        cax = ax.matshow(concat_images, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([]))\n",
    "    return cax\n",
    "\n",
    "\n",
    "def save_images(images, filename, **kwargs):\n",
    "    fig = plt.figure(1)\n",
    "    fig.clf()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plot_images(images, ax, **kwargs)\n",
    "    fig.patch.set_visible(False)\n",
    "    ax.patch.set_visible(False)\n",
    "    plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log_regression(images, labels, learning_rate, max_iter):\n",
    "    \"\"\" Used in Q1\n",
    "        Inputs: train_images, train_labels, learning rate,\n",
    "        and max num of iterations in gradient descent\n",
    "        Returns the trained weights (w/o intercept)\"\"\"\n",
    "    N_data, D_data = images.shape\n",
    "    K_data = labels.shape[1]\n",
    "    weights = np.zeros((D_data, K_data))\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        lny = log_softmax(images, weights)\n",
    "        E = cross_ent(lny, labels)\n",
    "        y = np.exp(lny)\n",
    "        err = y - labels\n",
    "        a = np.expand_dims(err, axis=1) * np.expand_dims(images, axis=2)\n",
    "        dE = np.sum(a,axis = 0)\n",
    "        weights = weights - learning_rate * dE\n",
    "        #acc = accuracy(lny, labels)\n",
    "        #print(acc,E)\n",
    "                \n",
    "    \n",
    "\n",
    "    w0 = None # No intercept for log-reg\n",
    "    return weights, w0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gda(images, labels):\n",
    "    \"\"\" Used in Q2\n",
    "        Inputs: train_images, train_labels\n",
    "        Returns the trained weights, the intercept, and D x K class means, \n",
    "        and D x D common covariance matrix.\"\"\"\n",
    "    N_data, D_data = images.shape\n",
    "    K_data = labels.shape[1]\n",
    "    \n",
    "    # mu\n",
    "    Mu = []\n",
    "    for i in range(K_data):\n",
    "        tk = labels[:,i]\n",
    "        muk = np.sum(images.T * tk, axis = 1)/np.sum(tk)\n",
    "        Mu.append(muk)\n",
    "    Mu = np.array(Mu).T\n",
    "    #print(Mu.shape)\n",
    "    \n",
    "    # sigma\n",
    "    Nk = np.sum(labels, axis = 0)\n",
    "    N = np.sum(labels)\n",
    "    \n",
    "    Sigma = []\n",
    "    for i in range(K_data):\n",
    "        nk = Nk[i]\n",
    "        muk = Mu[:,i]\n",
    "        Ck = (labels[:,i] == np.ones(N_data))\n",
    "        xk = images[Ck,:]\n",
    "        xn_muk = xk-muk\n",
    "        sigmak = np.cov(xn_muk.T)\n",
    "        Sigma.append(nk/N*sigmak)\n",
    "    Sigma = sum(Sigma)\n",
    "    \n",
    "    # weights\n",
    "    \n",
    "    try:\n",
    "        np.linalg.inv(Sigma)\n",
    "    except:\n",
    "        Sigma = Sigma + 1/N_data*np.identity(Sigma.shape[0])\n",
    "    \n",
    "    weights = np.linalg.inv(Sigma) @ Mu\n",
    "    \n",
    "    # w0\n",
    "    pCk = np.mean(labels, axis=0)\n",
    "    w0 = -1/2*np.diagonal(Mu.T @ weights) + np.log(pCk)\n",
    "    #print(w0.shape)\n",
    "\n",
    "    \n",
    "    return weights, w0, Mu, Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(images, weights, w0=None):\n",
    "    \"\"\" Used in Q1 and Q2\n",
    "        Inputs: images, and weights\n",
    "        Returns the log_softmax values.\"\"\"\n",
    "    if w0 is None: w0 = np.zeros(weights.shape[1])\n",
    "    \n",
    "    N_data, D_data = images.shape\n",
    "    \n",
    "    a = images @ weights + w0\n",
    "    b = logsumexp(a, axis=1, keepdims=True)\n",
    "    lny = a - b\n",
    "\n",
    "    return lny\n",
    "\n",
    "\n",
    "def cross_ent(log_Y, train_labels):\n",
    "    \"\"\" Used in Q1\n",
    "        Inputs: log of softmax values and training labels\n",
    "        Returns the cross entropy.\"\"\"\n",
    "\n",
    "    ce = - np.sum(train_labels * log_Y)\n",
    "    \n",
    "    return ce\n",
    "\n",
    "\n",
    "def predict(log_softmax):\n",
    "    \"\"\" Used in Q1 and Q2\n",
    "        Inputs: matrix of log softmax values\n",
    "        Returns the predictions\"\"\"\n",
    "\n",
    "    num = (log_softmax == np.max(log_softmax, axis = 1, keepdims = True))\n",
    "    pred = np.int32(num)\n",
    "        \n",
    "    return pred\n",
    "\n",
    "\n",
    "def accuracy(log_softmax, labels):\n",
    "    \"\"\" Used in Q1 and Q2\n",
    "        Inputs: matrix of log softmax values and 1-of-K labels\n",
    "        Returns the accuracy based on predictions from log likelihood values\"\"\"\n",
    "    \n",
    "    pred = predict(log_softmax)\n",
    "    \n",
    "    ac = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        acn = np.sum((pred[i,:]==1) == (labels[i,:]==1))== pred.shape[1]\n",
    "        ac.append(acn)\n",
    "    \n",
    "    acc = np.mean(ac)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    N_data = 10000 # Num of samples to be used in training\n",
    "    # Set this to a small number while experimenting.\n",
    "    # For log reg, finally use the entire training dataset for training (N_data=None).\n",
    "    # For gda, use as many training samples as your computer can handle.\n",
    "    \n",
    "    train_images, train_labels, test_images, test_labels = load_mnist(N_data)\n",
    "\n",
    "    # Q1: train logistic regression\n",
    "    #learning_rate, max_iter = .00001, 100\n",
    "    #weights, w0 = train_log_regression(train_images, train_labels, learning_rate, max_iter)\n",
    "    #save_images(weights.T, 'weights.png')\n",
    "\n",
    "    # Q2: train gaussian discriminant\n",
    "    weights, w0, Mu, Sigma = train_gda(train_images, train_labels)\n",
    "    save_images(Mu.T, 'means.png')\n",
    "\n",
    "    new_digit = 0\n",
    "    new_images = np.random.multivariate_normal(Mu[:, new_digit], Sigma, 10)\n",
    "    save_images((new_images > .5).astype(float), '0_images.png')\n",
    "\n",
    "    new_digit = 3\n",
    "    new_images = np.random.multivariate_normal(Mu[:, new_digit], Sigma, 10)\n",
    "    save_images((new_images > .5).astype(float), '3_images.png')\n",
    "\n",
    "    # evaluation\n",
    "    log_softmax_train = log_softmax(train_images, weights, w0)\n",
    "    log_softmax_test = log_softmax(test_images, weights, w0)\n",
    "    \n",
    "    train_accuracy = accuracy(log_softmax_train, train_labels)\n",
    "    test_accuracy = accuracy(log_softmax_test[:1000], test_labels[:1000])\n",
    "\n",
    "    print(\"Training accuracy is \", train_accuracy)\n",
    "    print(\"Test accuracy is \", test_accuracy)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
